{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssm951/chinese-genealogy/blob/main/Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Experimenting"
      ],
      "metadata": {
        "id": "uIksztG13hG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy (as baseline)"
      ],
      "metadata": {
        "id": "2Vv81eGQ3oUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA8nRzB3tPr6"
      },
      "outputs": [],
      "source": [
        "!pip install -q spacy\n",
        "!python -m spacy download zh_core_web_trf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import spacy\n",
        "spacy.require_cpu()\n",
        "print(spacy.__version__)\n",
        "nlp = spacy.load(\"zh_core_web_trf\")\n"
      ],
      "metadata": {
        "id": "D5KiH7cl687M",
        "outputId": "88a09f98-a3ef-4f84-9ef5-f717d21afd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"我叫孟庆延。你叫什么名字？\")\n",
        "for token in doc:\n",
        "    print(token.text,token.ent_iob_, token.ent_type_)"
      ],
      "metadata": {
        "id": "QR6J1iK67ObU",
        "outputId": "b66ceb2e-19ec-4803-f7bd-2c2b7379369f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "我 2 \n",
            "叫 2 \n",
            "孟庆延 3 PERSON\n",
            "。 2 \n",
            "你 2 \n",
            "叫 2 \n",
            "什么 2 \n",
            "名字 2 \n",
            "？ 2 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Chinese-Literature-NER-RE-Dataset"
      ],
      "metadata": {
        "id": "o5-nmoHSAQ8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es7OFigzAWrZ",
        "outputId": "0a32327f-1102-42be-a15b-2e693bb08dc2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Chinese-Literature-NER-RE-Dataset' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.training import Example\n",
        "\n",
        "def re_label_to_spacy(label):\n",
        "  split = label.split('_')\n",
        "  if len(split) == 1:\n",
        "    return 'O'\n",
        "  split[1] = split[1].replace('\\n','')\n",
        "  if split[1] == 'Thing':\n",
        "    return split[0] + '-PRODUCT'\n",
        "  if split[1] == 'Person':\n",
        "    return split[0] + '-PERSON'\n",
        "  if split[1] == 'Location':\n",
        "    return split[0] + '-LOC'\n",
        "  if split[1] == 'Time':\n",
        "    return split[0] + '-TIME'\n",
        "  if split[1] == 'Metric':\n",
        "    return split[0] + '-QUANTITY'\n",
        "  if split[1] == 'Organization':\n",
        "    return split[0] + '-ORG'\n",
        "  if split[1] == 'Abstract':\n",
        "    return split[0] + '-WORK_OF_ART'\n",
        "  print('Failed to parse', label)\n",
        "  return 'O'\n",
        "\n",
        "dataset_path = \"/content/Chinese-Literature-NER-RE-Dataset/ner/test.txt\"\n",
        "re_dataset = []\n",
        "text = \"\"\n",
        "entities = []\n",
        "count = 0\n",
        "with open(dataset_path) as my_file:\n",
        "  # Read line by line\n",
        "  for line in my_file:\n",
        "    split = line.split(' ')\n",
        "    if len(split) == 1:\n",
        "      doc = nlp(text)\n",
        "      for token in doc:\n",
        "        if (token.ent_type_):\n",
        "          tokenized = [];\n",
        "          entity_of_tokenized = []\n",
        "          new_token = \"\"\n",
        "          prev_ent = None\n",
        "          for i, char in enumerate(text):\n",
        "            entity = entities[i].split('-')\n",
        "            if entity[0] == 'B':\n",
        "              new_token = char\n",
        "              prev_ent = entities[i]\n",
        "            elif entity[0] == 'I':\n",
        "              new_token += char\n",
        "            elif len(new_token) != 0:\n",
        "              tokenized.append(new_token)\n",
        "              entity_of_tokenized.append(prev_ent)\n",
        "              new_token = \"\"\n",
        "          re_dataset.append((doc, {\"words\": tokenized, \"entities\": entity_of_tokenized}))\n",
        "          break\n",
        "      text = \"\"\n",
        "      entities = []\n",
        "      count += 1\n",
        "      if count == 100:\n",
        "        break\n",
        "    else:\n",
        "      text += split[0]\n",
        "      entities.append(re_label_to_spacy(split[1]))\n",
        "\n"
      ],
      "metadata": {
        "id": "8RIhTdaqAyjX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load custom dataset"
      ],
      "metadata": {
        "id": "4yuxGtGk8hk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cMy8oniG-m8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"/content/drive/MyDrive/Meng_FamilySearch/cleaned/\"\n",
        "dirs = os.listdir(filepath)\n",
        "words = []\n",
        "labels = []\n",
        "for dir in dirs:\n",
        "  with open(filepath + dir) as my_file:\n",
        "    data_array = my_file.readlines()\n",
        "    words += list(data_array[0])[:-1] # Remove new line\n",
        "    labels += list(data_array[1]) # second line are labels\n",
        "\n",
        "sample_data = \"\".join(words)"
      ],
      "metadata": {
        "id": "IQtZyGJk7ziv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data"
      ],
      "metadata": {
        "id": "sMNGN7VM_SMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(sample_data)"
      ],
      "metadata": {
        "id": "MtEv594a90Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_ent = False\n",
        "for token in doc:\n",
        "  if (token.ent_type_):\n",
        "    if not prev_ent:\n",
        "      print()\n",
        "    prev_ent = True\n",
        "    print(token.text,f'{token.ent_iob_}-{token.ent_type_}', spacy.explain(token.ent_type_))\n",
        "  else:\n",
        "    prev_ent = False\n",
        "    print(token.text, end='')"
      ],
      "metadata": {
        "id": "XbCCrjrc-Ohx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Spacy model"
      ],
      "metadata": {
        "id": "tsirhwr-Cd9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.scorer import Scorer\n",
        "\n",
        "scorer = Scorer()\n",
        "\n",
        "examples = []\n",
        "scorer = Scorer()\n",
        "for example in re_dataset:\n",
        "    example.predicted = nlp(str(example.predicted))\n",
        "    examples.append(example)\n",
        "scores = scorer.score(examples)"
      ],
      "metadata": {
        "id": "d7Jf0MkVCrMW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(re_dataset[0].predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zmuD7VP3eyPw",
        "outputId": "ff25f136-e247-4892-a781-5251fc6de418"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'清明是人们祭扫先人，怀念追思的日子。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nlp(str(re_dataset[0].predicted))"
      ],
      "metadata": {
        "id": "pCzNv2jQeVe8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for example in re_dataset:\n",
        "  doc = nlp(str(re_dataset[0].predicted))\n",
        "  for token in doc:\n",
        "    if (token.ent_type_):\n",
        "      print(doc)\n",
        "      print(token.text, token.ent_iob_, token.ent_type_)\n",
        "      continue"
      ],
      "metadata": {
        "id": "lllX5B7QYZ8E"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = Example.from_dict(re_dataset[0][0], {\"entities\": re_dataset[0][1]})\n"
      ],
      "metadata": {
        "id": "4x88H5mvEUuy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re_dataset[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCR_CFc5rxj6",
        "outputId": "914a71ac-4946-4687-8b6f-9b3d37653057"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'B-TIME',\n",
              " 'I-TIME',\n",
              " 'B-PERSON',\n",
              " 'I-PERSON',\n",
              " 'I-PERSON',\n",
              " 'I-PERSON',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'I-LOC',\n",
              " 'O',\n",
              " 'B-PRODUCT',\n",
              " 'I-PRODUCT',\n",
              " 'O',\n",
              " 'B-TIME',\n",
              " 'I-TIME',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug_doc(example.reference)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Ru16RMpL0k",
        "outputId": "fe0918ed-84e3-417d-bf34-344fe69ce10d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "诗人高翥 O \n",
            "南北山头 O \n",
            "墓田 O \n",
            "清明 O \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_doc(doc):\n",
        "  for token in doc:\n",
        "    print(token.text, token.ent_iob_, token.ent_type_)"
      ],
      "metadata": {
        "id": "MdJOPHqTR95d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"清明是人们祭扫先人，怀念追思的日子。\")"
      ],
      "metadata": {
        "id": "xEAjhKs9h2u6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_doc(re_dataset[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAB_Fxh_qGb9",
        "outputId": "6582720b-0618-4b46-f633-963a26385234"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正如 O \n",
            "宋代 B DATE\n",
            "诗人 O \n",
            "高翥 B PERSON\n",
            "所 O \n",
            "云 O \n",
            "“ O \n",
            "南北 B LOC\n",
            "山头 I LOC\n",
            "多 O \n",
            "墓田 O \n",
            "， O \n",
            "清明 O \n",
            "祭扫 O \n",
            "各 O \n",
            "纷然 O \n",
            "。 O \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re_dataset[0][1]\n",
        "\n",
        "example = Example.from_dict(re_dataset[0][0], re_dataset[0][1])"
      ],
      "metadata": {
        "id": "L4oLxIHkqNTN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zv2ndsRJv1xF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}